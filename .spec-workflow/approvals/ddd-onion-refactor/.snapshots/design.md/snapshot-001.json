{
  "id": "snapshot_1765715605165_qp6yq9vx0",
  "approvalId": "approval_1765715605155_dyx6jm76o",
  "approvalTitle": "DDD+Onionアーキテクチャへのリファクタリング設計書",
  "version": 1,
  "timestamp": "2025-12-14T12:33:25.165Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# 設計書（Design Document）\n\n## Overview\n\n本設計は、`lyric-talk`（日本語歌詞を素材として入力文を\"歌詞断片の組み合わせ\"で再現するCLIツール）を **DDD（Domain-Driven Design） + Onion Architecture** に沿った構造へゼロベースで再構築するものです。\n\n現状の実験的実装（`src/` 直下のフラットな構造）では、外部技術（spaCy/GiNZA、ファイルI/O、設定）とドメインロジック（モーラ分割、マッチング戦略）が密結合しており、拡張性とテスト容易性に課題があります。\n\n本設計では、以下を実現します：\n\n- **依存方向の逆転**: 内側（Domain/Application）は外側（Infrastructure/Interface）に依存しない\n- **ドメインロジックの明示化**: 「読み」「モーラ」「マッチング戦略」「歌詞コーパス」などを純粋な値オブジェクト/エンティティとして定義\n- **ユースケースの境界化**: 「歌詞インデックス構築」「入力文マッチング」「結果保存/参照」を明確に分離\n- **DB永続化**: マッチング結果をJSONファイルではなくローカルDB（DuckDB）に保存し、後から参照可能にする\n- **テスト容易性**: Port/Adapterパターンにより、外部依存（NLP、I/O、DB）を簡単にモック/スタブ化\n\n## Steering Document Alignment\n\n### Technical Standards (tech.md)\n\n本プロジェクトにはまだ `.spec-workflow/steering/tech.md` が存在しないため、以下の技術的判断を明示します：\n\n- **Python 3.12+**: 現行 `pyproject.toml` に準拠\n- **依存管理**: `uv` を使用したモダンなPython環境管理\n- **テスト**: `pytest` + `pytest-cov` + `pytest-xdist` による並列テスト実行\n- **Lint/Format**: `ruff` による高速なlint/format（`.github/instructions/testing.instructions.md` に従う）\n- **NLP**: spaCy + GiNZA（既存依存を維持）\n- **永続化**: DuckDB（既存依存 `duckdb>=1.4.3` を活用）\n- **設定管理**: `pydantic-settings` による環境変数/設定ファイル対応\n\n### Project Structure (structure.md)\n\n本プロジェクトにはまだ `.spec-workflow/steering/structure.md` が存在しないため、以下のディレクトリ構成を新規に定義します：\n\n```\nsrc/\n├── domain/                 # ドメイン層（外部依存なし）\n│   ├── __init__.py\n│   ├── models/            # エンティティ・値オブジェクト\n│   │   ├── __init__.py\n│   │   ├── token.py       # Token（表層形・読み・モーラ・位置情報）\n│   │   ├── reading.py     # Reading（読み正規化を含む値オブジェクト）\n│   │   ├── mora.py        # Mora（モーラ分割・結合ロジック）\n│   │   ├── lyrics.py      # LyricsCorpus（歌詞集合）\n│   │   ├── match.py       # MatchResult（マッチング結果）\n│   │   └── match_run.py   # MatchRun（実行メタデータ）\n│   └── services/          # ドメインサービス（複数エンティティにまたがる操作）\n│       ├── __init__.py\n│       └── matching_strategy.py  # マッチング戦略（表層→読み→モーラの優先順位）\n│\n├── application/           # アプリケーション層（ユースケース）\n│   ├── __init__.py\n│   ├── ports/            # 外部依存のインターフェース（抽象）\n│   │   ├── __init__.py\n│   │   ├── nlp_port.py           # 形態素解析・読み取得のPort\n│   │   ├── lyrics_source_port.py # 歌詞入力のPort\n│   │   └── repository_port.py    # DB永続化のPort\n│   └── use_cases/        # ユースケース\n│       ├── __init__.py\n│       ├── build_lyric_index.py  # 歌詞インデックス構築\n│       ├── match_text.py         # 入力文マッチング\n│       └── save_match_result.py  # マッチング結果保存\n│\n├── infrastructure/        # インフラストラクチャ層（外部技術の実装）\n│   ├── __init__.py\n│   ├── nlp/\n│   │   ├── __init__.py\n│   │   └── spacy_adapter.py      # spaCy+GiNZAを使ったNlpPortの実装\n│   ├── lyrics/\n│   │   ├── __init__.py\n│   │   ├── file_lyrics_source.py # ファイルから歌詞を読み込む実装\n│   │   └── text_lyrics_source.py # 文字列から直接受け取る実装\n│   ├── database/\n│   │   ├── __init__.py\n│   │   ├── duckdb_repository.py  # DuckDBを使ったRepositoryPortの実装\n│   │   └── schema.py             # テーブル定義（SQL DDL）\n│   └── config/\n│       ├── __init__.py\n│       └── settings.py           # pydantic-settingsによる設定クラス\n│\n└── interface/             # インターフェース層（CLI、将来的にはAPIなど）\n    ├── __init__.py\n    └── cli/\n        ├── __init__.py\n        └── main.py               # CLIエントリーポイント\n\ntests/\n├── unit/\n│   ├── domain/          # ドメインモデル・サービスのテスト\n│   ├── application/     # ユースケースのテスト（Port/Adapterをモック）\n│   ├── infrastructure/  # 個別アダプタのテスト（spaCy、DuckDB等）\n│   └── interface/       # CLIのテスト（エンドツーエンド的テスト）\n└── fixtures/           # テスト用データ（歌詞サンプルなど）\n```\n\n## Code Reuse Analysis\n\n### 既存コンポーネントの活用\n\n現行実装は実験的コードのため、**ゼロベースで再構築**します。ただし、以下の知見・ロジックは再利用・参考にします：\n\n- **モーラ分割ロジック（`src/mora.py`）**:\n  - `split_mora()` 関数のロジックは、`domain/models/mora.py` の値オブジェクトに移植\n  - 正規表現パターン（拗音・促音・長音の処理）をそのまま活用\n  - `normalize_reading()` も `domain/models/reading.py` に移植\n\n- **マッチング優先度ポリシー（`src/matcher.py`）**:\n  - 「表層形 → 読み → モーラ組み合わせ」の3段階マッチング戦略を、`domain/services/matching_strategy.py` に抽出\n  - `MatchType` 列挙型（`EXACT_SURFACE`, `EXACT_READING`, `MORA_COMBINATION`, `NO_MATCH`）は、`domain/models/match.py` に移植\n\n- **歌詞インデックス構造（`src/lyric_index.py`）**:\n  - 「表層形マップ」「読みマップ」「モーラセット」の概念は、`domain/models/lyrics.py` の `LyricsCorpus` エンティティに継承\n  - ただし、spaCy型への直接依存は排除し、純粋なドメイン型（`Token`）で構成\n\n- **設定管理（`src/config.py`）**:\n  - `pydantic-settings` を使った環境変数対応の仕組みは、`infrastructure/config/settings.py` にそのまま移植\n  - `max_mora_length` 設定はドメインに影響するため、ユースケース層で注入できるようにする\n\n### 削除される既存実装\n\n- **`src/main.py`**: CLI エントリーポイントは `interface/cli/main.py` として再実装\n- **`src/lyric_index.py`**: ドメイン層 + アプリケーション層に分割再実装\n- **`src/matcher.py`**: ドメイン層 + アプリケーション層に分割再実装\n- **`src/mora.py`**: `domain/models/mora.py` と `domain/models/reading.py` に分割移植\n\n### Integration Points\n\n- **既存のNLP依存（spaCy + GiNZA）**: `infrastructure/nlp/spacy_adapter.py` でラップし、アプリケーション層からは `NlpPort` 経由で利用\n- **既存のDB（DuckDB）**: `infrastructure/database/duckdb_repository.py` で永続化を実装し、アプリケーション層からは `RepositoryPort` 経由で利用\n- **既存のテストフレームワーク（pytest）**: `tests/unit/` 配下に新しいテスト構造を作成（Onionレイヤごとに整理）\n\n## Architecture\n\n### Onion Architecture の依存方向\n\n```mermaid\ngraph TD\n    subgraph \"Interface Layer\"\n        CLI[CLI Main]\n    end\n    \n    subgraph \"Infrastructure Layer\"\n        SpacyAdapter[SpaCy Adapter]\n        FileLyricsSource[File Lyrics Source]\n        DuckDBRepo[DuckDB Repository]\n        Settings[Settings]\n    end\n    \n    subgraph \"Application Layer\"\n        BuildIndex[Build Lyric Index Use Case]\n        MatchText[Match Text Use Case]\n        SaveResult[Save Match Result Use Case]\n        NlpPort[NLP Port<br/>(interface)]\n        LyricsPort[Lyrics Source Port<br/>(interface)]\n        RepoPort[Repository Port<br/>(interface)]\n    end\n    \n    subgraph \"Domain Layer\"\n        Token[Token]\n        Reading[Reading]\n        Mora[Mora]\n        LyricsCorpus[Lyrics Corpus]\n        MatchResult[Match Result]\n        MatchingStrategy[Matching Strategy<br/>(Domain Service)]\n    end\n    \n    CLI --> BuildIndex\n    CLI --> MatchText\n    CLI --> SaveResult\n    \n    BuildIndex --> NlpPort\n    BuildIndex --> LyricsPort\n    BuildIndex --> LyricsCorpus\n    BuildIndex --> Token\n    \n    MatchText --> NlpPort\n    MatchText --> MatchingStrategy\n    MatchText --> Token\n    MatchText --> MatchResult\n    \n    SaveResult --> RepoPort\n    SaveResult --> MatchResult\n    \n    SpacyAdapter -.implements.-> NlpPort\n    FileLyricsSource -.implements.-> LyricsPort\n    DuckDBRepo -.implements.-> RepoPort\n    \n    MatchingStrategy --> Token\n    MatchingStrategy --> Reading\n    MatchingStrategy --> Mora\n    MatchingStrategy --> MatchResult\n    \n    style Domain Layer fill:#e1f5fe\n    style Application Layer fill:#fff3e0\n    style Infrastructure Layer fill:#f3e5f5\n    style Interface Layer fill:#e8f5e9\n```\n\n### Modular Design Principles\n\n- **Single File Responsibility**: 各ファイルは1つの責務（1つの値オブジェクト、1つのユースケース、1つのアダプタ）のみを持つ\n- **Component Isolation**: ドメインモデルは外部技術から完全に隔離され、純粋なPython型のみで構成\n- **Service Layer Separation**: \n  - Domain Service（`matching_strategy.py`）: ドメインロジック（複数エンティティにまたがる操作）\n  - Application Service（`use_cases/`）: ユースケース（外部依存の組み立て・調整）\n  - Infrastructure Service（`infrastructure/`）: 外部技術の実装\n- **Utility Modularity**: モーラ分割、読み正規化などは、値オブジェクト内のメソッドとして実装（関数ではなくオブジェクト指向的に）\n\n### 依存性の逆転（Dependency Inversion）\n\nアプリケーション層は **Port（インターフェース）** を定義し、インフラストラクチャ層がそれを実装します：\n\n- **NlpPort**: 形態素解析・読み取得の抽象\n  - `tokenize(text: str) -> List[TokenData]`: 文字列をトークン化し、読み情報を返す\n- **LyricsSourcePort**: 歌詞入力の抽象\n  - `load_lyrics() -> str`: 歌詞文字列を取得\n- **RepositoryPort**: DB永続化の抽象\n  - `save_match_run(run: MatchRun) -> str`: 実行メタデータを保存し、run_idを返す\n  - `save_lyric_tokens(run_id: str, tokens: List[Token]) -> None`: 歌詞トークンを保存\n  - `save_match_results(run_id: str, results: List[MatchResult]) -> None`: マッチング結果を保存\n  - `get_match_run(run_id: str) -> MatchRun`: 実行メタデータを取得\n  - `get_match_results(run_id: str) -> List[MatchResult]`: マッチング結果を取得（歌詞トークン情報を解決済み）\n\n## Components and Interfaces\n\n### Domain Layer\n\n#### `domain/models/token.py`\n\n- **Purpose:** 歌詞トークンを表す値オブジェクト（表層形・読み・基本形・品詞・モーラ・位置情報）\n- **Interfaces:**\n  - `Token(surface, reading, lemma, pos, line_index, token_index)`: コンストラクタ\n  - `moras: List[Mora]`: モーラのリスト（`Reading` から自動生成）\n- **Dependencies:** `Reading`, `Mora`\n- **Reuses:** 現行の `src/lyric_index.py` の `Token` dataclass の構造を継承（ただし、spaCy型への依存を排除）\n\n#### `domain/models/reading.py`\n\n- **Purpose:** 読み（カタカナ）を表す値オブジェクト（正規化ロジックを含む）\n- **Interfaces:**\n  - `Reading(raw: str)`: コンストラクタ（ひらがな/カタカナの自動正規化）\n  - `normalized: str`: 正規化された読み（カタカナ）\n  - `to_moras() -> List[Mora]`: モーラに分割\n- **Dependencies:** なし（純粋な値オブジェクト）\n- **Reuses:** `src/mora.py` の `normalize_reading()`, `hiragana_to_katakana()` のロジックを移植\n\n#### `domain/models/mora.py`\n\n- **Purpose:** モーラ（音節）を表す値オブジェクト（分割ロジックを含む）\n- **Interfaces:**\n  - `Mora(value: str)`: コンストラクタ\n  - `@staticmethod split(katakana: str) -> List[Mora]`: カタカナ文字列をモーラに分割\n- **Dependencies:** なし\n- **Reuses:** `src/mora.py` の `split_mora()` のロジックを移植\n\n#### `domain/models/lyrics.py`\n\n- **Purpose:** 歌詞コーパス（全トークン + 検索用インデックス）を表すエンティティ\n- **Interfaces:**\n  - `LyricsCorpus(tokens: List[Token])`: コンストラクタ\n  - `find_by_surface(surface: str) -> List[Token]`: 表層形で検索\n  - `find_by_reading(reading: Reading) -> List[Token]`: 読みで検索\n  - `has_mora(mora: Mora) -> bool`: モーラが含まれるかチェック\n  - `find_by_mora(mora: Mora) -> List[Token]`: モーラを含むトークンを検索\n- **Dependencies:** `Token`, `Reading`, `Mora`\n- **Reuses:** `src/lyric_index.py` の `LyricIndex` の構造を継承\n\n#### `domain/models/match.py`\n\n- **Purpose:** マッチング結果を表す値オブジェクト\n- **Interfaces:**\n  - `MatchResult(input_token, input_reading, match_type, matched_token_ids, mora_details)`: コンストラクタ\n  - `match_type: MatchType`: マッチタイプ（列挙型: `EXACT_SURFACE`, `EXACT_READING`, `MORA_COMBINATION`, `NO_MATCH`）\n  - `matched_token_ids: List[str]`: マッチした歌詞トークンのID（**リレーション参照として保持**）\n  - `mora_details: Optional[MoraMatchDetails]`: モーラマッチの詳細\n- **Dependencies:** `Token`（型参照のみ）\n- **Reuses:** `src/matcher.py` の `MatchResult`, `MatchType`, `MoraMatch` の概念を継承（ただし、リレーション指向に変更）\n\n#### `domain/models/match_run.py`\n\n- **Purpose:** マッチング実行のメタデータを表すエンティティ\n- **Interfaces:**\n  - `MatchRun(run_id, timestamp, input_text, config)`: コンストラクタ\n  - `run_id: str`: 一意なID（UUID）\n  - `timestamp: datetime`: 実行日時\n  - `input_text: str`: 入力文\n  - `config: dict`: 実行時の設定値（`max_mora_length` など）\n- **Dependencies:** なし\n- **Reuses:** なし（新規設計）\n\n#### `domain/services/matching_strategy.py`\n\n- **Purpose:** マッチング戦略を実装するドメインサービス（優先度: 表層→読み→モーラ）\n- **Interfaces:**\n  - `match_token(input_token: Token, lyrics_corpus: LyricsCorpus, max_mora_length: int) -> MatchResult`: 1トークンをマッチング\n- **Dependencies:** `Token`, `Reading`, `Mora`, `LyricsCorpus`, `MatchResult`\n- **Reuses:** `src/matcher.py` の `Matcher._match_single_token()` のロジックを移植（ただし、spaCy依存を排除）\n\n### Application Layer\n\n#### `application/ports/nlp_port.py`\n\n- **Purpose:** 形態素解析・読み取得の抽象インターフェース\n- **Interfaces:**\n  - `@abstractmethod tokenize(text: str) -> List[TokenData]`: 文字列をトークン化（`TokenData` はDTOで、表層・読み・基本形・品詞を含む）\n- **Dependencies:** なし（抽象）\n- **Reuses:** なし（新規設計）\n\n#### `application/ports/lyrics_source_port.py`\n\n- **Purpose:** 歌詞入力の抽象インターフェース\n- **Interfaces:**\n  - `@abstractmethod load_lyrics() -> str`: 歌詞文字列を取得\n- **Dependencies:** なし（抽象）\n- **Reuses:** なし（新規設計）\n\n#### `application/ports/repository_port.py`\n\n- **Purpose:** DB永続化の抽象インターフェース\n- **Interfaces:**\n  - `@abstractmethod save_match_run(run: MatchRun) -> str`: 実行メタデータを保存\n  - `@abstractmethod save_lyric_tokens(run_id: str, tokens: List[Token]) -> None`: 歌詞トークンを保存\n  - `@abstractmethod save_match_results(run_id: str, results: List[MatchResult]) -> None`: マッチング結果を保存\n  - `@abstractmethod get_match_run(run_id: str) -> MatchRun`: 実行メタデータを取得\n  - `@abstractmethod get_match_results(run_id: str) -> List[MatchResult]`: マッチング結果を取得（歌詞トークン情報を解決）\n- **Dependencies:** `MatchRun`, `Token`, `MatchResult`\n- **Reuses:** なし（新規設計）\n\n#### `application/use_cases/build_lyric_index.py`\n\n- **Purpose:** 歌詞をインデックス化するユースケース\n- **Interfaces:**\n  - `BuildLyricIndexUseCase(nlp_port: NlpPort, lyrics_source_port: LyricsSourcePort)`\n  - `execute() -> LyricsCorpus`: 歌詞をロード・トークン化してLyricsCorpusを構築\n- **Dependencies:** `NlpPort`, `LyricsSourcePort`, `LyricsCorpus`, `Token`, `Reading`, `Mora`\n- **Reuses:** `src/lyric_index.py` の `LyricIndex.from_lyrics()` のロジックを移植（ただし、Port経由で依存注入）\n\n#### `application/use_cases/match_text.py`\n\n- **Purpose:** 入力文をマッチングするユースケース\n- **Interfaces:**\n  - `MatchTextUseCase(nlp_port: NlpPort, matching_strategy: MatchingStrategy)`\n  - `execute(input_text: str, lyrics_corpus: LyricsCorpus, max_mora_length: int) -> List[MatchResult]`: 入力文をマッチング\n- **Dependencies:** `NlpPort`, `MatchingStrategy`, `LyricsCorpus`, `MatchResult`\n- **Reuses:** `src/matcher.py` の `Matcher.match()` のロジックを移植\n\n#### `application/use_cases/save_match_result.py`\n\n- **Purpose:** マッチング結果を保存するユースケース\n- **Interfaces:**\n  - `SaveMatchResultUseCase(repository_port: RepositoryPort)`\n  - `execute(run: MatchRun, lyric_tokens: List[Token], results: List[MatchResult]) -> str`: 結果をDBに保存し、run_idを返す\n- **Dependencies:** `RepositoryPort`, `MatchRun`, `Token`, `MatchResult`\n- **Reuses:** なし（新規設計）\n\n### Infrastructure Layer\n\n#### `infrastructure/nlp/spacy_adapter.py`\n\n- **Purpose:** spaCy + GiNZA を使った `NlpPort` の実装\n- **Interfaces:**\n  - `SpacyAdapter(model_name: str = \"ja_ginza\")`: コンストラクタ（spaCyモデルをロード）\n  - `tokenize(text: str) -> List[TokenData]`: 文字列をトークン化\n- **Dependencies:** `spacy`, `NlpPort`\n- **Reuses:** 現行の `src/lyric_index.py` と `src/matcher.py` のspaCy呼び出しロジックを移植\n\n#### `infrastructure/lyrics/file_lyrics_source.py`\n\n- **Purpose:** ファイルから歌詞を読み込む `LyricsSourcePort` の実装\n- **Interfaces:**\n  - `FileLyricsSource(file_path: str)`: コンストラクタ\n  - `load_lyrics() -> str`: ファイルを読み込んで歌詞文字列を返す\n- **Dependencies:** `pathlib.Path`, `LyricsSourcePort`\n- **Reuses:** `src/main.py` のファイル読み込みロジックを移植\n\n#### `infrastructure/lyrics/text_lyrics_source.py`\n\n- **Purpose:** 文字列から直接受け取る `LyricsSourcePort` の実装\n- **Interfaces:**\n  - `TextLyricsSource(text: str)`: コンストラクタ\n  - `load_lyrics() -> str`: 文字列をそのまま返す\n- **Dependencies:** `LyricsSourcePort`\n- **Reuses:** `src/main.py` の `--lyrics-text` オプションのロジックを移植\n\n#### `infrastructure/database/duckdb_repository.py`\n\n- **Purpose:** DuckDB を使った `RepositoryPort` の実装\n- **Interfaces:**\n  - `DuckDBRepository(db_path: str = \"lyric_talk.duckdb\")`: コンストラクタ（DBファイルを開く/作成）\n  - `save_match_run(run: MatchRun) -> str`: 実行メタデータを保存\n  - `save_lyric_tokens(run_id: str, tokens: List[Token]) -> None`: 歌詞トークンを保存\n  - `save_match_results(run_id: str, results: List[MatchResult]) -> None`: マッチング結果を保存\n  - `get_match_run(run_id: str) -> MatchRun`: 実行メタデータを取得\n  - `get_match_results(run_id: str) -> List[MatchResult]`: マッチング結果を取得（JOINで歌詞トークン情報を解決）\n- **Dependencies:** `duckdb`, `RepositoryPort`, `MatchRun`, `Token`, `MatchResult`\n- **Reuses:** なし（新規設計）\n\n#### `infrastructure/database/schema.py`\n\n- **Purpose:** DuckDB テーブル定義（DDL）\n- **Interfaces:** SQL文字列定数\n  - `CREATE_MATCH_RUN_TABLE`: `match_runs` テーブル（run_id, timestamp, input_text, config_json）\n  - `CREATE_LYRIC_TOKEN_TABLE`: `lyric_tokens` テーブル（token_id, run_id, surface, reading, lemma, pos, line_index, token_index, moras_json）\n  - `CREATE_MATCH_RESULT_TABLE`: `match_results` テーブル（result_id, run_id, input_token, input_reading, match_type, matched_token_ids_json, mora_details_json）\n- **Dependencies:** なし\n- **Reuses:** なし（新規設計）\n\n#### `infrastructure/config/settings.py`\n\n- **Purpose:** pydantic-settings による設定管理\n- **Interfaces:**\n  - `Settings`: `max_mora_length`, `db_path`, `spacy_model` などの設定値\n- **Dependencies:** `pydantic-settings`\n- **Reuses:** `src/config.py` をそのまま移植・拡張\n\n### Interface Layer\n\n#### `interface/cli/main.py`\n\n- **Purpose:** CLI エントリーポイント\n- **Interfaces:**\n  - `main() -> None`: `argparse` で引数を解析し、ユースケースを組み立てて実行\n- **Dependencies:** `argparse`, `BuildLyricIndexUseCase`, `MatchTextUseCase`, `SaveMatchResultUseCase`, `SpacyAdapter`, `FileLyricsSource`, `TextLyricsSource`, `DuckDBRepository`, `Settings`\n- **Reuses:** `src/main.py` のCLI引数パース・実行フローを移植（ただし、ユースケース経由で実行）\n\n## Data Models\n\n### Domain Models（Pure Python）\n\n#### `Token`（値オブジェクト）\n\n```python\n@dataclass(frozen=True)\nclass Token:\n    surface: str           # 表層形\n    reading: Reading       # 読み（値オブジェクト）\n    lemma: str            # 基本形\n    pos: str              # 品詞\n    line_index: int       # 行番号\n    token_index: int      # 行内トークン番号\n    \n    @property\n    def moras(self) -> List[Mora]:\n        return self.reading.to_moras()\n    \n    @property\n    def token_id(self) -> str:\n        # ユニークID（run_id + line_index + token_index で後から生成）\n        return f\"{self.line_index}_{self.token_index}\"\n```\n\n#### `Reading`（値オブジェクト）\n\n```python\n@dataclass(frozen=True)\nclass Reading:\n    raw: str  # 元の読み（ひらがな/カタカナ混在可）\n    \n    @property\n    def normalized(self) -> str:\n        # カタカナに正規化\n        return normalize_to_katakana(self.raw)\n    \n    def to_moras(self) -> List[Mora]:\n        return Mora.split(self.normalized)\n```\n\n#### `Mora`（値オブジェクト）\n\n```python\n@dataclass(frozen=True)\nclass Mora:\n    value: str  # 1モーラ（例: \"ト\", \"キョ\", \"ファ\"）\n    \n    @staticmethod\n    def split(katakana: str) -> List[Mora]:\n        # 正規表現でモーラ分割（現行の split_mora() ロジック）\n        ...\n```\n\n#### `LyricsCorpus`（エンティティ）\n\n```python\n@dataclass\nclass LyricsCorpus:\n    tokens: List[Token]\n    _surface_index: Dict[str, List[Token]]   # 表層形 → トークン\n    _reading_index: Dict[str, List[Token]]   # 読み → トークン\n    _mora_index: Dict[str, List[Token]]      # モーラ → トークン\n    _mora_set: Set[str]                      # 全モーラのセット\n    \n    def __post_init__(self):\n        # インデックスを構築\n        ...\n    \n    def find_by_surface(self, surface: str) -> List[Token]:\n        ...\n    \n    def find_by_reading(self, reading: Reading) -> List[Token]:\n        ...\n    \n    def has_mora(self, mora: Mora) -> bool:\n        ...\n    \n    def find_by_mora(self, mora: Mora) -> List[Token]:\n        ...\n```\n\n#### `MatchResult`（値オブジェクト）\n\n```python\n@dataclass(frozen=True)\nclass MatchResult:\n    input_token: str\n    input_reading: str\n    match_type: MatchType  # Enum\n    matched_token_ids: List[str]  # 歌詞トークンIDのリスト（リレーション参照）\n    mora_details: Optional[MoraMatchDetails]  # モーラマッチの詳細\n\n@dataclass(frozen=True)\nclass MoraMatchDetails:\n    moras: List[str]\n    source_token_ids: List[str]  # 各モーラの元トークンID\n    mora_indices: List[int]      # 各モーラのトークン内位置\n\nclass MatchType(Enum):\n    EXACT_SURFACE = \"exact_surface\"\n    EXACT_READING = \"exact_reading\"\n    MORA_COMBINATION = \"mora_combination\"\n    NO_MATCH = \"no_match\"\n```\n\n#### `MatchRun`（エンティティ）\n\n```python\n@dataclass\nclass MatchRun:\n    run_id: str         # UUID\n    timestamp: datetime\n    input_text: str\n    config: dict        # {\"max_mora_length\": 5, ...}\n```\n\n### Database Schema（DuckDB）\n\n#### `match_runs` テーブル\n\n```sql\nCREATE TABLE IF NOT EXISTS match_runs (\n    run_id VARCHAR PRIMARY KEY,\n    timestamp TIMESTAMP NOT NULL,\n    input_text TEXT NOT NULL,\n    config_json TEXT NOT NULL  -- JSON形式の設定値\n);\n```\n\n#### `lyric_tokens` テーブル\n\n```sql\nCREATE TABLE IF NOT EXISTS lyric_tokens (\n    token_id VARCHAR PRIMARY KEY,          -- \"{run_id}_{line_index}_{token_index}\"\n    run_id VARCHAR NOT NULL,\n    surface VARCHAR NOT NULL,\n    reading VARCHAR NOT NULL,\n    lemma VARCHAR NOT NULL,\n    pos VARCHAR NOT NULL,\n    line_index INTEGER NOT NULL,\n    token_index INTEGER NOT NULL,\n    moras_json TEXT NOT NULL,              -- JSON配列: [\"ト\", \"ウ\", \"キョ\", \"ウ\"]\n    FOREIGN KEY (run_id) REFERENCES match_runs(run_id)\n);\n\nCREATE INDEX idx_lyric_tokens_run_id ON lyric_tokens(run_id);\n```\n\n#### `match_results` テーブル\n\n```sql\nCREATE TABLE IF NOT EXISTS match_results (\n    result_id VARCHAR PRIMARY KEY,         -- UUID\n    run_id VARCHAR NOT NULL,\n    input_token VARCHAR NOT NULL,\n    input_reading VARCHAR NOT NULL,\n    match_type VARCHAR NOT NULL,           -- \"exact_surface\", \"exact_reading\", etc.\n    matched_token_ids_json TEXT,           -- JSON配列: [\"run_xxx_0_1\", \"run_xxx_2_3\"]\n    mora_details_json TEXT,                -- JSON: {\"moras\": [...], \"source_token_ids\": [...], ...}\n    FOREIGN KEY (run_id) REFERENCES match_runs(run_id)\n);\n\nCREATE INDEX idx_match_results_run_id ON match_results(run_id);\n```\n\n### DTO（Data Transfer Object）\n\n#### `TokenData`（Application層でNlpPortから返される）\n\n```python\n@dataclass(frozen=True)\nclass TokenData:\n    surface: str\n    reading: str\n    lemma: str\n    pos: str\n```\n\n## Error Handling\n\n### Error Scenarios\n\n#### Scenario 1: 歌詞ファイルが見つからない（ファイル読み込み時）\n\n- **Handling:** `FileLyricsSource.load_lyrics()` が `FileNotFoundError` を送出\n- **User Impact:** CLI が `\"エラー: 歌詞ファイルが見つかりません: {path}\"` を表示し、終了コード1で終了\n\n#### Scenario 2: spaCyモデルがロードできない（NLP初期化時）\n\n- **Handling:** `SpacyAdapter.__init__()` が `OSError` を送出（モデル未インストール）\n- **User Impact:** CLI が `\"エラー: spaCyモデル 'ja_ginza' がロードできません。以下のコマンドでインストールしてください: python -m spacy download ja_ginza\"` を表示し、終了コード1で終了\n\n#### Scenario 3: DB保存時のエラー（書き込み権限不足など）\n\n- **Handling:** `DuckDBRepository.save_match_run()` が `duckdb.Error` を送出\n- **User Impact:** CLI が `\"エラー: 結果の保存に失敗しました: {error}\"` を表示し、終了コード1で終了\n\n#### Scenario 4: マッチング結果が全て `NO_MATCH`（入力文が歌詞と全く一致しない）\n\n- **Handling:** `MatchTextUseCase.execute()` は正常に終了（エラーではない）\n- **User Impact:** CLI は結果をDBに保存し、`\"警告: マッチング結果がありません。歌詞に含まれない単語が多い可能性があります。\"` を表示\n\n#### Scenario 5: 引数が不正（--lyrics と --lyrics-text の両方が未指定）\n\n- **Handling:** `argparse` がエラーを検出せず、CLI の主処理で検証\n- **User Impact:** CLI が `\"エラー: --lyrics または --lyrics-text のいずれかを指定してください\"` を表示し、終了コード1で終了\n\n## Testing Strategy\n\n### Unit Testing\n\n#### Domain Layer（外部依存なし、純粋な値オブジェクト/サービス）\n\n- **`domain/models/token.py`**: `Token` のプロパティ（`moras`, `token_id`）が正しく計算されるか\n- **`domain/models/reading.py`**: `normalize_to_katakana()` が正しく動作するか（ひらがな→カタカナ変換）\n- **`domain/models/mora.py`**: `Mora.split()` が正しくモーラ分割するか（拗音・促音・長音の処理）\n  - テストケース: `\"トウキョウ\" -> [\"ト\", \"ウ\", \"キョ\", \"ウ\"]`, `\"ファイティング\" -> [\"ファ\", \"イ\", \"ティ\", \"ン\", \"グ\"]`\n- **`domain/models/lyrics.py`**: `LyricsCorpus` のインデックス構築・検索が正しく動作するか\n- **`domain/services/matching_strategy.py`**: 優先度順マッチングが正しく動作するか（表層→読み→モーラの順に試行）\n\n#### Application Layer（Port/Adapterをモック化）\n\n- **`application/use_cases/build_lyric_index.py`**: モック `NlpPort` + モック `LyricsSourcePort` で歌詞インデックスが構築できるか\n- **`application/use_cases/match_text.py`**: モック `NlpPort` + モック `MatchingStrategy` でマッチングが実行できるか\n- **`application/use_cases/save_match_result.py`**: モック `RepositoryPort` で結果が保存されるか（保存メソッドが呼ばれるか）\n\n#### Infrastructure Layer（個別アダプタの動作確認）\n\n- **`infrastructure/nlp/spacy_adapter.py`**: 実際にspaCyをロードして、簡単なテキストをトークン化できるか\n  - **注意**: spaCyのロードが遅いため、テストはスキップ可能にする（`@pytest.mark.slow`）\n- **`infrastructure/database/duckdb_repository.py`**: 一時DBファイルを作成して、CRUD操作が正しく動作するか\n  - テストケース: `save_match_run()` → `get_match_run()` でデータが復元されるか\n  - テストケース: `save_lyric_tokens()` + `save_match_results()` → `get_match_results()` で歌詞トークン情報が解決されるか\n\n### Integration Testing\n\n#### End-to-End Scenario（CLI実行シミュレーション）\n\n- **`tests/unit/interface/test_cli.py`**: \n  - モックされた各アダプタを組み合わせて、CLI の `main()` 関数を実行\n  - 引数パース → ユースケース実行 → 結果保存までの一連の流れが正常に動作するか\n\n#### 実際のspaCy + DuckDBを使った統合テスト（オプション）\n\n- **`tests/integration/test_full_pipeline.py`**:\n  - 実際にspaCyをロードし、簡単な歌詞とテキストでマッチングを実行\n  - DuckDBに保存された結果を取得し、説明可能な情報が含まれているか検証\n  - **注意**: 実行時間が長いため、CIでは選択的に実行（`@pytest.mark.integration`）\n\n### Test Coverage Goals\n\n- **Domain Layer**: 100%（外部依存がないため、完全にテスト可能）\n- **Application Layer**: 90%以上（Port/Adapterをモック化してテスト）\n- **Infrastructure Layer**: 70%以上（実際の外部ライブラリを使うため、一部テスト困難な箇所は許容）\n- **Interface Layer**: 80%以上（CLI引数パースとユースケース組み立て）\n\n### Test Organization\n\n```\ntests/\n├── unit/\n│   ├── domain/\n│   │   ├── models/\n│   │   │   ├── test_token.py\n│   │   │   ├── test_reading.py\n│   │   │   ├── test_mora.py\n│   │   │   ├── test_lyrics.py\n│   │   │   └── test_match.py\n│   │   └── services/\n│   │       └── test_matching_strategy.py\n│   ├── application/\n│   │   └── use_cases/\n│   │       ├── test_build_lyric_index.py\n│   │       ├── test_match_text.py\n│   │       └── test_save_match_result.py\n│   ├── infrastructure/\n│   │   ├── nlp/\n│   │   │   └── test_spacy_adapter.py  # @pytest.mark.slow\n│   │   ├── lyrics/\n│   │   │   ├── test_file_lyrics_source.py\n│   │   │   └── test_text_lyrics_source.py\n│   │   └── database/\n│   │       └── test_duckdb_repository.py\n│   └── interface/\n│       └── cli/\n│           └── test_main.py\n├── integration/\n│   └── test_full_pipeline.py  # @pytest.mark.integration\n└── fixtures/\n    ├── sample_lyrics.txt\n    └── sample_input.txt\n```\n\n## Implementation Notes\n\n### モーラ組み合わせマッチングのアルゴリズム\n\n現行の `src/matcher.py` では、入力トークンの各モーラを歌詞の全トークンから探し、組み合わせてマッチングを実現しています。この処理は、`domain/services/matching_strategy.py` に移植されます。\n\nアルゴリズムの概要：\n\n1. 入力トークンのモーラリストを取得（例: `[\"ト\", \"ウ\", \"キョ\", \"ウ\"]`）\n2. 各モーラについて、歌詞コーパスから「そのモーラを含むトークン」を検索\n3. 見つかった場合、そのトークンからモーラを取得し、次のモーラを続けて探索\n4. 全モーラがマッチした場合、`MatchResult` を生成（`match_type=MORA_COMBINATION`）\n\n### DB永続化の設計意図\n\nマッチング結果をDBに保存することで、以下が可能になります：\n\n- **説明可能性**: 「どの歌詞トークンから取ってきたか」を後から参照可能（リレーション経由で歌詞トークン情報を取得）\n- **再利用性**: 同じ歌詞で複数の入力文をマッチングした結果を比較・分析可能\n- **拡張性**: 将来的に「類似度スコア」「ユーザーフィードバック」などのカラムを追加可能\n\n### CLIの互換性\n\n現行の `src/main.py` のCLI引数と動作を維持します：\n\n- `--lyrics` / `--lyrics-text`: 歌詞入力（既存と同じ）\n- `--text`: 入力文（既存と同じ）\n- `--output`: **削除**（DBに保存されるため、ファイル出力オプションは不要）\n- `--max-mora-length`: 既存と同じ（設定値の上書き）\n\n新しいCLIでは、実行結果として `run_id` が表示され、ユーザーは以下のコマンドで結果を参照できます（将来的な拡張として）：\n\n```bash\nlyric-talk query --run-id <UUID>  # 結果を参照（将来実装）\n```\n\n### テスト実行の効率化\n\nspaCyのロードは遅いため、以下のマーカーを活用します：\n\n- `@pytest.mark.slow`: spaCyを実際にロードするテスト\n- `@pytest.mark.integration`: 実際のDB + NLPを使う統合テスト\n\n通常のテスト実行では、これらをスキップします：\n\n```bash\nuv run pytest -m \"not slow and not integration\"\n```\n\nCI環境では、すべてのテストを実行します：\n\n```bash\nuv run pytest\n```\n\n## Migration Plan\n\n### Phase 1: ドメイン層の実装\n\n1. `domain/models/` 配下の値オブジェクトを実装（`Token`, `Reading`, `Mora`, `LyricsCorpus`, `MatchResult`, `MatchRun`）\n2. `domain/services/matching_strategy.py` を実装\n3. ドメイン層の単体テストを実装・実行（100%カバレッジ目標）\n\n### Phase 2: アプリケーション層の実装\n\n1. `application/ports/` 配下のインターフェースを定義\n2. `application/use_cases/` 配下のユースケースを実装\n3. アプリケーション層の単体テスト（モックを使用）を実装・実行\n\n### Phase 3: インフラストラクチャ層の実装\n\n1. `infrastructure/nlp/spacy_adapter.py` を実装\n2. `infrastructure/lyrics/` 配下のアダプタを実装\n3. `infrastructure/database/` 配下（スキーマ + リポジトリ）を実装\n4. `infrastructure/config/settings.py` を実装\n5. インフラストラクチャ層の単体テストを実装・実行\n\n### Phase 4: インターフェース層の実装\n\n1. `interface/cli/main.py` を実装（既存の `src/main.py` を参考にしつつ、ユースケース経由で実行）\n2. `pyproject.toml` の `[project.scripts]` を更新（新しいエントリーポイント）\n3. インターフェース層のテストを実装・実行\n\n### Phase 5: 統合テスト & 既存実装の削除\n\n1. 統合テストを実装・実行（実際のspaCy + DuckDBを使用）\n2. 既存の `src/main.py`, `src/lyric_index.py`, `src/matcher.py`, `src/mora.py`, `src/config.py` を削除\n3. 最終的なlint/format + 全テスト実行\n\n### Phase 6: ドキュメント更新\n\n1. `README.md` を更新（新しいアーキテクチャの説明、使い方の更新）\n2. 必要に応じて `.spec-workflow/steering/` 配下にドキュメント追加（`tech.md`, `structure.md`）\n\n## Next Steps\n\n本設計書の承認後、以下のタスク分解（`tasks.md`）を作成し、実装フェーズに移行します。\n\n主要なタスク：\n\n1. ドメインモデルの実装（`Token`, `Reading`, `Mora`, `LyricsCorpus`, `MatchResult`, `MatchRun`）\n2. ドメインサービスの実装（`MatchingStrategy`）\n3. Portインターフェースの定義\n4. ユースケースの実装（`BuildLyricIndex`, `MatchText`, `SaveMatchResult`）\n5. spaCyアダプタの実装\n6. 歌詞入力アダプタの実装\n7. DuckDBリポジトリの実装\n8. CLIエントリーポイントの実装\n9. テストの実装（ドメイン → アプリケーション → インフラ → インターフェース → 統合）\n10. 既存実装の削除 & ドキュメント更新\n",
  "fileStats": {
    "size": 38315,
    "lines": 831,
    "lastModified": "2025-12-14T12:33:18.073Z"
  },
  "comments": []
}