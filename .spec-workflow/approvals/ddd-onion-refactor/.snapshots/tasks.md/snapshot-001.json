{
  "id": "snapshot_1765723743530_nst9limnm",
  "approvalId": "approval_1765723743523_wzg2uvj1l",
  "approvalTitle": "DDD + Onion Architecture - タスクドキュメント承認リクエスト",
  "version": 1,
  "timestamp": "2025-12-14T14:49:03.530Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# タスクドキュメント（Tasks Document）\n\n## Overview\n\n本ドキュメントは、`lyric-talk` を **DDD + Onion Architecture** に沿って再構築するための実装タスクを定義します。設計書（design.md）で示された構造に従い、以下の順序で実装を進めます：\n\n1. **Domain層**: 値オブジェクト、エンティティ、Portインターフェース\n2. **Infrastructure層**: Repository実装、NLP実装、DB Schema\n3. **Application層**: ユースケース\n4. **Interface層**: CLI\n5. **テスト**: 各レイヤのテスト\n\n各タスクは1〜3ファイルの作成・変更に限定し、段階的に実装できるよう分割しています。\n\n---\n\n## Phase 1: Domain層 - 基礎モデルとPort定義\n\n### Task 1.1: 値オブジェクト - Mora\n\n- [ ] 1.1. Create Mora value object\n  - File: [src/domain/models/mora.py](src/domain/models/mora.py)\n  - モーラ（音節）を表す値オブジェクトを作成\n  - `Mora.split(katakana: str) -> List[Mora]` でカタカナをモーラに分割\n  - pydantic BaseModel を使用、immutable設定\n  - _Leverage: 既存の `src/mora.py` のロジックを参考（正規表現パターン）_\n  - _Requirements: Requirement 2_\n  - _Prompt: \n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in DDD and value objects | Task: Create Mora value object in src/domain/models/mora.py following Requirement 2 (ドメインモデルの明確化). Implement immutable value object using pydantic BaseModel with `value: str` field and static method `split(katakana: str) -> List[Mora]` that uses regex to split katakana into moras. Refer to existing src/mora.py for regex patterns (拗音・促音・長音の処理). | Restrictions: No external dependencies beyond pydantic, must be immutable (frozen=True), no I/O or NLP libraries | Leverage: src/mora.py (existing regex logic) | Success: Mora is immutable, split() correctly handles 拗音/促音/長音, unit tests pass\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 1.2: 値オブジェクト - Reading\n\n- [ ] 1.2. Create Reading value object\n  - File: [src/domain/models/reading.py](src/domain/models/reading.py)\n  - 読み（カタカナ）を表す値オブジェクトを作成\n  - `normalized` プロパティで正規化された読みを返す\n  - `to_moras() -> List[Mora]` でモーラに分割\n  - pydantic BaseModel を使用、immutable設定\n  - _Leverage: 既存の `src/mora.py` の `normalize_reading()` を参考_\n  - _Requirements: Requirement 2_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in DDD and value objects | Task: Create Reading value object in src/domain/models/reading.py following Requirement 2. Implement immutable value object using pydantic BaseModel with `raw: str` field, computed property `normalized` (normalizes to katakana), and method `to_moras() -> List[Mora]` that delegates to Mora.split(). Refer to existing src/mora.py for normalize_reading() logic. | Restrictions: No external dependencies beyond pydantic, must be immutable (frozen=True), depends only on Mora | Leverage: src/mora.py (normalize_reading logic), src/domain/models/mora.py | Success: Reading is immutable, normalized handles hiragana->katakana, to_moras() works correctly\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 1.3: エンティティ - LyricToken\n\n- [ ] 1.3. Create LyricToken entity\n  - File: [src/domain/models/lyric_token.py](src/domain/models/lyric_token.py)\n  - 歌詞トークンを表すエンティティを作成（集約ルート）\n  - `token_id`, `moras` を computed property として実装\n  - pydantic BaseModel を使用（mutableエンティティ）\n  - _Leverage: Reading, Mora_\n  - _Requirements: Requirement 2_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in DDD entities | Task: Create LyricToken entity in src/domain/models/lyric_token.py following Requirement 2. Implement mutable entity using pydantic BaseModel with fields: lyrics_corpus_id, surface, reading (Reading object), lemma, pos, line_index, token_index. Add computed properties: token_id (formatted as {lyrics_corpus_id}_{line_index}_{token_index}), moras (calls reading.to_moras()). | Restrictions: Entity is mutable (frozen=False), depends only on Reading and Mora | Leverage: src/domain/models/reading.py, src/domain/models/mora.py | Success: LyricToken is mutable entity, token_id generates correctly, moras property works\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 1.4: エンティティ - LyricsCorpus と MatchRun\n\n- [ ] 1.4. Create LyricsCorpus and MatchRun entities\n  - Files: [src/domain/models/lyrics_corpus.py](src/domain/models/lyrics_corpus.py), [src/domain/models/match_run.py](src/domain/models/match_run.py)\n  - LyricsCorpus: 歌詞コーパスメタデータのエンティティ（LyricTokenは含まない）\n  - MatchRun: マッチング実行メタデータのエンティティ\n  - pydantic BaseModel を使用（mutableエンティティ）\n  - _Requirements: Requirement 2, Requirement 6_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in DDD entities | Task: Create LyricsCorpus entity in src/domain/models/lyrics_corpus.py and MatchRun entity in src/domain/models/match_run.py following Requirements 2 and 6 (DB永続化). LyricsCorpus has: lyrics_corpus_id (str, UUID), content_hash (str, SHA256), title (Optional[str]), created_at (datetime). MatchRun has: run_id (str, UUID), lyrics_corpus_id (str), timestamp (datetime), input_text (str), config (Dict[str, Any]). Both use pydantic BaseModel, mutable (frozen=False). | Restrictions: No external dependencies beyond pydantic, datetime, typing | Success: Both entities are well-defined with proper types\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 1.5: 値オブジェクト - MatchResult\n\n- [ ] 1.5. Create MatchResult value object\n  - File: [src/domain/models/match_result.py](src/domain/models/match_result.py)\n  - マッチング結果を表す値オブジェクトを作成\n  - `MatchType` 列挙型（EXACT_SURFACE, EXACT_READING, MORA_COMBINATION, NO_MATCH）\n  - `MoraMatchDetail` 値オブジェクト（mora, source_token_id, mora_index）\n  - pydantic BaseModel を使用、immutable設定\n  - _Leverage: 既存の `src/matcher.py` のMatchType_\n  - _Requirements: Requirement 2, Requirement 6_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in DDD value objects and enums | Task: Create MatchResult value object in src/domain/models/match_result.py following Requirements 2 and 6. Define MatchType enum (str, Enum) with values: EXACT_SURFACE, EXACT_READING, MORA_COMBINATION, NO_MATCH. Define MoraMatchDetail value object (mora, source_token_id, mora_index). Define MatchResult value object (input_token, input_reading, match_type, matched_token_ids, mora_details). All use pydantic BaseModel, immutable (frozen=True). | Restrictions: No external dependencies beyond pydantic, enum, typing | Leverage: src/matcher.py (existing MatchType concept) | Success: All value objects are immutable, MatchType enum is well-defined\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 1.6: Portインターフェース - Repository群\n\n- [ ] 1.6. Create Repository Port interfaces\n  - Files: [src/domain/repositories/lyric_token_repository.py](src/domain/repositories/lyric_token_repository.py), [src/domain/repositories/lyrics_repository.py](src/domain/repositories/lyrics_repository.py), [src/domain/repositories/match_repository.py](src/domain/repositories/match_repository.py)\n  - LyricTokenRepository: save_tokens, find_by_surface, find_by_reading, find_by_mora, has_mora\n  - LyricsRepository: save_corpus, get_corpus, find_by_hash\n  - MatchRepository: save_match_run, save_match_results, get_match_run, get_match_results\n  - すべて abstract base class (ABC) として定義\n  - _Requirements: Requirement 4 (Port/Adapter)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in DDD repository patterns and dependency inversion | Task: Create three Repository Port interfaces in src/domain/repositories/ following Requirement 4 (Port/Adapter). LyricTokenRepository (save_tokens, find_by_surface, find_by_reading, find_by_mora, has_mora), LyricsRepository (save_corpus, get_corpus, find_by_hash), MatchRepository (save_match_run, save_match_results, get_match_run, get_match_results). All methods are @abstractmethod. Use ABC from abc module. | Restrictions: Interfaces only (no implementation), depends only on domain models | Leverage: src/domain/models/*.py | Success: All repository interfaces are well-defined with clear method signatures\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 1.7: Portインターフェース - NlpService\n\n- [ ] 1.7. Create NlpService Port interface and TokenData DTO\n  - Files: [src/domain/services/nlp_service.py](src/domain/services/nlp_service.py), [src/application/dtos/token_data.py](src/application/dtos/token_data.py)\n  - NlpService: tokenize(text: str) -> List[TokenData] の抽象メソッド\n  - TokenData: DTO (surface, reading, lemma, pos, line_index, token_index)\n  - NlpService は abstract base class (ABC) として定義\n  - _Requirements: Requirement 4 (Port/Adapter)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in DDD ports and DTOs | Task: Create NlpService Port interface in src/domain/services/nlp_service.py and TokenData DTO in src/application/dtos/token_data.py following Requirement 4 (Port/Adapter). NlpService has abstract method tokenize(text: str) -> List[TokenData]. TokenData is pydantic BaseModel with fields: surface, reading, lemma, pos, line_index, token_index (all str except indexes which are int). | Restrictions: NlpService is abstract (ABC), TokenData is simple DTO (no logic) | Success: NlpService interface is clear, TokenData is well-typed\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 1.8: ドメインサービス - MatchingStrategy\n\n- [ ] 1.8. Create MatchingStrategy domain service\n  - File: [src/domain/services/matching_strategy.py](src/domain/services/matching_strategy.py)\n  - マッチング戦略を実装するドメインサービス（優先度: 表層→読み→モーラ）\n  - `match_token(input_token_data: TokenData, lyrics_corpus_id: str, max_mora_length: int) -> MatchResult`\n  - Repository経由でLyricTokenを検索（メモリ展開しない）\n  - _Leverage: LyricTokenRepository, LyricToken, Reading, Mora, MatchResult, 既存の `src/matcher.py` のロジック_\n  - _Requirements: Requirement 2, Requirement 3_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in DDD domain services | Task: Create MatchingStrategy domain service in src/domain/services/matching_strategy.py following Requirements 2 and 3. Implement match_token(input_token_data: TokenData, lyrics_corpus_id: str, max_mora_length: int) -> MatchResult with 3-stage matching strategy: 1) exact surface match, 2) exact reading match, 3) mora combination match. Use LyricTokenRepository for searches (no memory loading). Return appropriate MatchType and matched_token_ids. | Restrictions: Use only domain models and repository port, no direct DB access | Leverage: src/domain/repositories/lyric_token_repository.py, src/domain/models/*.py, src/matcher.py (existing matching logic) | Success: MatchingStrategy implements 3-stage priority correctly, uses Repository for searches\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n---\n\n## Phase 2: Infrastructure層 - DB Schema と Repository実装\n\n### Task 2.1: DB Schema 定義\n\n- [ ] 2.1. Define DuckDB schema\n  - File: [src/infrastructure/database/schema.py](src/infrastructure/database/schema.py)\n  - テーブル定義（lyrics_corpus, lyric_tokens, match_runs, match_results）\n  - インデックス定義（検索性能最適化）\n  - `initialize_database(db_path: str) -> None` 関数\n  - _Requirements: Requirement 6 (DB永続化)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Database Engineer specializing in schema design and DuckDB | Task: Create database schema in src/infrastructure/database/schema.py following Requirement 6 (DB永続化). Define 4 tables: lyrics_corpus (lyrics_corpus_id, content_hash UNIQUE, title, created_at), lyric_tokens (token_id, lyrics_corpus_id FK, surface, reading, lemma, pos, line_index, token_index, moras_json TEXT), match_runs (run_id, lyrics_corpus_id FK, timestamp, input_text, config_json TEXT), match_results (result_id, run_id FK, input_token, input_reading, match_type, matched_token_ids_json TEXT, mora_details_json TEXT). Add indexes for performance. Implement initialize_database() function. | Restrictions: Use DuckDB SQL syntax only, ensure foreign key constraints | Success: Schema creates all tables with proper constraints and indexes\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: functions and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 2.2: DuckDB LyricTokenRepository 実装\n\n- [ ] 2.2. Implement DuckDB LyricTokenRepository\n  - File: [src/infrastructure/database/duckdb_lyric_token_repository.py](src/infrastructure/database/duckdb_lyric_token_repository.py)\n  - LyricTokenRepository の具象実装\n  - save_tokens, find_by_surface, find_by_reading, find_by_mora, has_mora を実装\n  - JSON検索でモーラを検索\n  - _Leverage: LyricTokenRepository Port, schema.py_\n  - _Requirements: Requirement 4 (Port/Adapter), Requirement 6_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in repository pattern and DuckDB | Task: Implement DuckDBLyricTokenRepository in src/infrastructure/database/duckdb_lyric_token_repository.py following Requirements 4 and 6. Implement all methods from LyricTokenRepository interface: save_tokens (batch insert), find_by_surface (WHERE surface=?), find_by_reading (WHERE reading=?), find_by_mora (search moras_json with json_contains or LIKE), has_mora (check existence). Convert LyricToken domain model to/from DB rows. | Restrictions: Implement LyricTokenRepository interface exactly, use duckdb library, no memory loading | Leverage: src/domain/repositories/lyric_token_repository.py, src/infrastructure/database/schema.py | Success: All repository methods work correctly with DuckDB, domain models are properly converted\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 2.3: DuckDB LyricsRepository と MatchRepository 実装\n\n- [ ] 2.3. Implement DuckDB LyricsRepository and MatchRepository\n  - Files: [src/infrastructure/database/duckdb_lyrics_repository.py](src/infrastructure/database/duckdb_lyrics_repository.py), [src/infrastructure/database/duckdb_match_repository.py](src/infrastructure/database/duckdb_match_repository.py)\n  - LyricsRepository の具象実装: save_corpus, get_corpus, find_by_hash\n  - MatchRepository の具象実装: save_match_run, save_match_results, get_match_run, get_match_results\n  - _Leverage: Repository Ports, schema.py_\n  - _Requirements: Requirement 4 (Port/Adapter), Requirement 6_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in repository pattern and DuckDB | Task: Implement DuckDBLyricsRepository in src/infrastructure/database/duckdb_lyrics_repository.py and DuckDBMatchRepository in src/infrastructure/database/duckdb_match_repository.py following Requirements 4 and 6. LyricsRepository implements: save_corpus (insert with content_hash uniqueness check), get_corpus (SELECT by ID), find_by_hash (SELECT by content_hash). MatchRepository implements: save_match_run (insert run metadata), save_match_results (batch insert results), get_match_run (SELECT by run_id), get_match_results (SELECT by run_id). Convert domain models to/from DB rows, handle JSON serialization for config/matched_token_ids/mora_details. | Restrictions: Implement interfaces exactly, use duckdb library | Leverage: src/domain/repositories/*.py, src/infrastructure/database/schema.py | Success: Both repositories work correctly, domain models are properly converted\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 2.4: SpaCy NlpService 実装\n\n- [ ] 2.4. Implement SpaCy NlpService\n  - File: [src/infrastructure/nlp/spacy_nlp_service.py](src/infrastructure/nlp/spacy_nlp_service.py)\n  - NlpService の具象実装（spaCy + GiNZA）\n  - tokenize(text: str) -> List[TokenData] を実装\n  - 行ごとに処理し、line_index/token_index を付与\n  - _Leverage: NlpService Port, 既存の spaCy/GiNZA 設定_\n  - _Requirements: Requirement 4 (Port/Adapter)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in NLP and spaCy | Task: Implement SpacyNlpService in src/infrastructure/nlp/spacy_nlp_service.py following Requirement 4 (Port/Adapter). Implement NlpService interface with tokenize(text: str) -> List[TokenData] method. Load spaCy model \"ja_ginza\" in __init__, process text line-by-line, extract surface, reading (katakana_reading or orth_), lemma, pos for each token, assign line_index and token_index. Return List[TokenData]. | Restrictions: Implement NlpService interface exactly, use spacy library (>=3.7.0), handle errors gracefully | Leverage: src/domain/services/nlp_service.py, src/application/dtos/token_data.py, tech.md (spaCy version info) | Success: SpacyNlpService loads ja_ginza model, tokenize() returns correct TokenData list with proper indexes\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 2.5: 設定管理 - Settings\n\n- [ ] 2.5. Create Settings configuration\n  - File: [src/infrastructure/config/settings.py](src/infrastructure/config/settings.py)\n  - pydantic-settings を使った設定管理\n  - 環境変数接頭辞: `LYRIC_TALK_`\n  - DB接続、NLPモデル名などの設定項目\n  - _Leverage: 既存の `src/config.py`_\n  - _Requirements: tech.md (設定管理)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in configuration management and pydantic-settings | Task: Create Settings class in src/infrastructure/config/settings.py following tech.md standards (pydantic-settings, prefix LYRIC_TALK_). Define settings: db_path (default: \"lyric_talk.duckdb\"), nlp_model_name (default: \"ja_ginza\"), max_mora_length (default: 5). Use pydantic-settings BaseSettings with env_prefix=\"LYRIC_TALK_\". Support .env file loading. | Restrictions: Use pydantic-settings library, follow tech.md conventions | Leverage: src/config.py (existing structure), tech.md | Success: Settings loads from environment variables and .env file correctly\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n---\n\n## Phase 3: Application層 - ユースケース\n\n### Task 3.1: RegisterLyricsUseCase\n\n- [ ] 3.1. Implement RegisterLyricsUseCase\n  - File: [src/application/use_cases/register_lyrics.py](src/application/use_cases/register_lyrics.py)\n  - 歌詞をDBに登録するユースケース\n  - execute(lyrics_text: str, title: Optional[str] = None) -> str (lyrics_corpus_id を返す)\n  - 既存歌詞（ハッシュ）が登録済みなら既存IDを返す\n  - _Leverage: NlpService, LyricTokenRepository, LyricsRepository_\n  - _Requirements: Requirement 3 (ユースケース)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in application layer and use cases | Task: Implement RegisterLyricsUseCase in src/application/use_cases/register_lyrics.py following Requirement 3 (ユースケース). Use case receives lyrics_text and optional title, computes SHA256 hash, checks if already registered via LyricsRepository.find_by_hash(), if not: tokenizes via NlpService, creates LyricsCorpus entity, saves via LyricsRepository, creates LyricToken entities, saves via LyricTokenRepository. Returns lyrics_corpus_id. | Restrictions: Use only Port interfaces (no direct implementation), ensure idempotency with hash check | Leverage: src/domain/services/nlp_service.py, src/domain/repositories/*.py, src/domain/models/*.py | Success: RegisterLyricsUseCase registers lyrics correctly, reuses existing corpus on duplicate hash\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 3.2: MatchTextUseCase\n\n- [ ] 3.2. Implement MatchTextUseCase\n  - File: [src/application/use_cases/match_text.py](src/application/use_cases/match_text.py)\n  - 入力文をマッチングするユースケース\n  - execute(lyrics_corpus_id: str, input_text: str, max_mora_length: int = 5) -> str (run_id を返す)\n  - NlpService でトークン化、MatchingStrategy で各トークンをマッチング、結果を MatchRepository に保存\n  - _Leverage: NlpService, MatchingStrategy, MatchRepository_\n  - _Requirements: Requirement 3 (ユースケース)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in application layer and use cases | Task: Implement MatchTextUseCase in src/application/use_cases/match_text.py following Requirement 3 (ユースケース). Use case receives lyrics_corpus_id, input_text, max_mora_length, tokenizes input via NlpService, creates MatchRun entity with timestamp/config, saves via MatchRepository, for each input token calls MatchingStrategy.match_token(), collects MatchResult list, saves via MatchRepository. Returns run_id. | Restrictions: Use only Port interfaces, no direct implementation | Leverage: src/domain/services/nlp_service.py, src/domain/services/matching_strategy.py, src/domain/repositories/match_repository.py | Success: MatchTextUseCase performs matching correctly, saves run and results to DB\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 3.3: QueryResultsUseCase\n\n- [ ] 3.3. Implement QueryResultsUseCase\n  - File: [src/application/use_cases/query_results.py](src/application/use_cases/query_results.py)\n  - マッチング結果を取得するユースケース\n  - execute(run_id: str) -> Dict (実行メタデータ + 結果（LyricToken情報解決済み）を返す)\n  - MatchRepository で結果取得、LyricTokenRepository でトークン情報を解決\n  - _Leverage: MatchRepository, LyricTokenRepository_\n  - _Requirements: Requirement 3 (ユースケース), Requirement 6_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in application layer and use cases | Task: Implement QueryResultsUseCase in src/application/use_cases/query_results.py following Requirements 3 and 6. Use case receives run_id, retrieves MatchRun via MatchRepository.get_match_run(), retrieves MatchResult list via MatchRepository.get_match_results(), for each result resolves matched_token_ids to LyricToken details via LyricTokenRepository, returns Dict with run metadata and results (with token details). | Restrictions: Use only Port interfaces, ensure all token references are resolved | Leverage: src/domain/repositories/match_repository.py, src/domain/repositories/lyric_token_repository.py | Success: QueryResultsUseCase returns complete results with token details resolved\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: classes with methods and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n---\n\n## Phase 4: Interface層 - CLI\n\n### Task 4.1: CLI Main - エントリポイント\n\n- [ ] 4.1. Implement CLI main entry point\n  - File: [src/interface/cli/main.py](src/interface/cli/main.py)\n  - CLIエントリポイント（argparse）\n  - サブコマンド: register, match, query\n  - 依存性注入（Infrastructure実装をインスタンス化してUseCase に渡す）\n  - _Leverage: すべてのUseCase、Repository実装、NlpService実装、Settings_\n  - _Requirements: Requirement 5 (CLI互換), Requirement 7 (ゼロベース再構築)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in CLI applications and dependency injection | Task: Implement CLI main entry point in src/interface/cli/main.py following Requirements 5 and 7. Use argparse to define 3 subcommands: register (--lyrics FILE or --lyrics-text TEXT, --title), match (--corpus-id ID, --text TEXT, --max-mora-length), query (--run-id ID). In main(), instantiate Settings, initialize DB, create concrete implementations (SpacyNlpService, DuckDB repositories), inject into use cases, execute appropriate use case based on subcommand. Handle errors gracefully with user-friendly messages. | Restrictions: CLI must be user-friendly, handle all error scenarios, use only concrete implementations from infrastructure layer | Leverage: src/application/use_cases/*.py, src/infrastructure/**/*.py, src/infrastructure/config/settings.py | Success: CLI runs all 3 subcommands correctly, errors are handled gracefully\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: functions and location)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 4.2: pyproject.toml エントリポイント更新\n\n- [ ] 4.2. Update pyproject.toml entry point\n  - File: [pyproject.toml](pyproject.toml)\n  - `[project.scripts]` を更新: `lyric-talk = \"src.interface.cli.main:main\"`\n  - 既存コード（`src/main.py`）の削除は後のタスクで実施\n  - _Requirements: Requirement 7 (ゼロベース再構築)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Python Developer specializing in packaging and entry points | Task: Update pyproject.toml entry point following Requirement 7 (ゼロベース再構築). Change [project.scripts] section to: lyric-talk = \"src.interface.cli.main:main\". This replaces the old entry point (src.main:main). | Restrictions: Only modify [project.scripts] section, do not break other configurations | Leverage: pyproject.toml (existing file) | Success: Entry point points to new CLI main, can be invoked via lyric-talk command after installation\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: filesModified)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n---\n\n## Phase 5: テスト\n\n### Task 5.1: Domain層ユニットテスト\n\n- [ ] 5.1. Write unit tests for Domain layer\n  - Files: [tests/unit/domain/test_mora.py](tests/unit/domain/test_mora.py), [tests/unit/domain/test_reading.py](tests/unit/domain/test_reading.py), [tests/unit/domain/test_lyric_token.py](tests/unit/domain/test_lyric_token.py), [tests/unit/domain/test_match_result.py](tests/unit/domain/test_match_result.py)\n  - 値オブジェクト、エンティティのプロパティ・メソッドをテスト\n  - pytest を使用\n  - _Leverage: Domain models_\n  - _Requirements: Requirement 8 (テスト)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: QA Engineer specializing in unit testing and pytest | Task: Write comprehensive unit tests for Domain layer models in tests/unit/domain/ following Requirement 8 (テスト). Test: Mora.split() with various katakana inputs (拗音/促音/長音), Reading.normalized and to_moras(), LyricToken computed properties (token_id, moras), MatchResult value object construction. Use pytest, ensure good coverage, test edge cases. | Restrictions: Test domain models in isolation (no external dependencies) | Leverage: src/domain/models/*.py, pytest | Success: All domain models have comprehensive unit tests, tests pass and cover edge cases\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: filesCreated)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 5.2: MatchingStrategy ユニットテスト\n\n- [ ] 5.2. Write unit tests for MatchingStrategy\n  - File: [tests/unit/domain/test_matching_strategy.py](tests/unit/domain/test_matching_strategy.py)\n  - モックRepository でテスト（3段階マッチング戦略を検証）\n  - pytest + unittest.mock を使用\n  - _Leverage: MatchingStrategy, mock LyricTokenRepository_\n  - _Requirements: Requirement 8 (テスト)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: QA Engineer specializing in unit testing and mocking | Task: Write comprehensive unit tests for MatchingStrategy in tests/unit/domain/test_matching_strategy.py following Requirement 8 (テスト). Mock LyricTokenRepository, test 3-stage matching: 1) exact surface (returns EXACT_SURFACE), 2) exact reading (returns EXACT_READING), 3) mora combination (returns MORA_COMBINATION), 4) no match (returns NO_MATCH). Verify that matching stops at first successful stage. Use pytest + unittest.mock. | Restrictions: Mock all repository dependencies, test business logic in isolation | Leverage: src/domain/services/matching_strategy.py, unittest.mock | Success: MatchingStrategy logic is fully tested with mocked repository, all scenarios covered\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: filesCreated)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 5.3: Application層ユニットテスト\n\n- [ ] 5.3. Write unit tests for Application layer use cases\n  - Files: [tests/unit/application/test_register_lyrics.py](tests/unit/application/test_register_lyrics.py), [tests/unit/application/test_match_text.py](tests/unit/application/test_match_text.py), [tests/unit/application/test_query_results.py](tests/unit/application/test_query_results.py)\n  - Port/Adapterをモック化してテスト\n  - pytest + unittest.mock を使用\n  - _Leverage: Use cases, mock Ports_\n  - _Requirements: Requirement 8 (テスト)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: QA Engineer specializing in use case testing and mocking | Task: Write comprehensive unit tests for Application layer use cases in tests/unit/application/ following Requirement 8 (テスト). Mock all Port interfaces (NlpService, repositories). Test: RegisterLyricsUseCase (new registration, duplicate hash reuse), MatchTextUseCase (matching flow, result saving), QueryResultsUseCase (result retrieval, token resolution). Verify use case orchestration logic. Use pytest + unittest.mock. | Restrictions: Mock all external dependencies (ports), test orchestration logic only | Leverage: src/application/use_cases/*.py, unittest.mock | Success: All use cases have comprehensive unit tests with mocked dependencies, orchestration logic verified\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: filesCreated)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 5.4: Infrastructure層テスト\n\n- [ ] 5.4. Write tests for Infrastructure layer\n  - Files: [tests/unit/infrastructure/test_duckdb_repositories.py](tests/unit/infrastructure/test_duckdb_repositories.py), [tests/unit/infrastructure/test_spacy_nlp_service.py](tests/unit/infrastructure/test_spacy_nlp_service.py)\n  - Repository: 一時DBファイルでCRUD操作をテスト\n  - NlpService: 簡単なテキストで動作確認（`@pytest.mark.slow`）\n  - pytest を使用\n  - _Leverage: Repository実装、NlpService実装_\n  - _Requirements: Requirement 8 (テスト)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: QA Engineer specializing in integration testing with real dependencies | Task: Write tests for Infrastructure layer in tests/unit/infrastructure/ following Requirement 8 (テスト). Test DuckDB repositories with temporary DB file: save/retrieve operations for all repositories. Test SpacyNlpService with simple Japanese text (mark as @pytest.mark.slow). Verify correct data persistence and retrieval. Use pytest, ensure cleanup of temp DB files. | Restrictions: Use real DuckDB and spaCy (not mocks), ensure test isolation with temp files | Leverage: src/infrastructure/database/*.py, src/infrastructure/nlp/spacy_nlp_service.py, pytest, tempfile | Success: All infrastructure components tested with real dependencies, tests are isolated and cleanup properly\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: filesCreated)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 5.5: 統合テスト\n\n- [ ] 5.5. Write integration tests\n  - File: [tests/integration/test_full_pipeline.py](tests/integration/test_full_pipeline.py)\n  - 実際のspaCy + DuckDBで、register → match → query の一連の流れをテスト\n  - `@pytest.mark.integration` を使用\n  - pytest を使用\n  - _Leverage: CLI main, すべてのコンポーネント_\n  - _Requirements: Requirement 8 (テスト)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: QA Engineer specializing in end-to-end integration testing | Task: Write integration tests in tests/integration/test_full_pipeline.py following Requirement 8 (テスト). Test full pipeline with real spaCy + DuckDB: 1) Register lyrics via RegisterLyricsUseCase, 2) Match input text via MatchTextUseCase, 3) Query results via QueryResultsUseCase. Verify results are complete and correct. Use temporary DB file, mark as @pytest.mark.integration. | Restrictions: Use real dependencies (not mocks), ensure test isolation with temp DB | Leverage: src/application/use_cases/*.py, src/infrastructure/**/*.py, pytest, tempfile | Success: Full pipeline integration test passes, verifies end-to-end functionality\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: filesCreated)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n---\n\n## Phase 6: クリーンアップと移行\n\n### Task 6.1: 既存コードの削除\n\n- [ ] 6.1. Remove old experimental code\n  - Files to delete: [src/main.py](src/main.py), [src/config.py](src/config.py), [src/lyric_index.py](src/lyric_index.py), [src/matcher.py](src/matcher.py), [src/mora.py](src/mora.py)\n  - 既存の実験的コードを削除（新アーキテクチャへの完全移行）\n  - _Requirements: Requirement 7 (ゼロベース再構築)_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Developer specializing in code cleanup and refactoring | Task: Remove old experimental code following Requirement 7 (ゼロベース再構築). Delete files: src/main.py, src/config.py, src/lyric_index.py, src/matcher.py, src/mora.py. These are replaced by new DDD + Onion Architecture implementation. Verify no references to these files exist in the new codebase. | Restrictions: Only delete specified files, ensure new implementation is complete before deletion | Success: Old experimental code is removed, new architecture is fully functional\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: filesModified/deleted)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 6.2: ドキュメント更新\n\n- [ ] 6.2. Update README with new architecture\n  - File: [README.md](README.md)\n  - 新アーキテクチャの説明、使用方法、開発ガイドを追加\n  - _Requirements: すべての要件_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: Technical Writer specializing in software documentation | Task: Update README.md to document new DDD + Onion Architecture. Include: architecture overview (layers: Domain, Application, Infrastructure, Interface), usage examples (register, match, query commands), development guide (testing, linting), dependencies. Replace outdated PoC information with new architecture details. | Restrictions: Keep documentation concise and user-friendly, include practical examples | Success: README clearly explains new architecture and how to use the CLI\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include artifacts: filesModified)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n### Task 6.3: 最終動作確認\n\n- [ ] 6.3. Final verification and testing\n  - すべてのテストを実行: `uv run pytest`\n  - Lintを実行: `uv run ruff check .`\n  - Formatを実行: `uv run ruff format .`\n  - CLIを実行して動作確認: `lyric-talk register`, `lyric-talk match`, `lyric-talk query`\n  - _Requirements: すべての要件_\n  - _Prompt:\n    \n    Implement the task for spec ddd-onion-refactor, first run spec-workflow-guide to get the workflow guide then implement the task:\n    \n    Role: QA Engineer specializing in final verification | Task: Perform final verification of the entire implementation. Run: 1) uv run pytest (all tests should pass), 2) uv run ruff check . (no lint errors), 3) uv run ruff format . (code formatted), 4) Manual CLI testing (register lyrics, match text, query results). Verify all requirements are met. Document any issues found. | Restrictions: Do not proceed if critical issues found, ensure all quality checks pass | Success: All tests pass, no lint errors, CLI works correctly, all requirements verified\n    \n    Instructions:\n    - Mark this task as in-progress [-] in tasks.md before starting\n    - After completion, log implementation with log-implementation tool (include summary of verification results)\n    - Mark this task as completed [x] in tasks.md after logging_\n\n---\n\n## Summary\n\n**Total Tasks**: 27 tasks across 6 phases\n\n**Implementation Order**:\n1. Domain層（8タスク）: 基礎となる値オブジェクト、エンティティ、Portを定義\n2. Infrastructure層（5タスク）: DB Schema と Repository/NLP実装\n3. Application層（3タスク）: ユースケース実装\n4. Interface層（2タスク）: CLI実装\n5. テスト（5タスク）: 各レイヤのテスト\n6. クリーンアップ（3タスク）: 既存コード削除、ドキュメント更新、最終確認\n\n**Dependencies**:\n- Phase 1 → Phase 2 → Phase 3 → Phase 4 の順序で実装\n- テスト（Phase 5）は各フェーズ完了後に並行実施可能\n- クリーンアップ（Phase 6）は最後に実施\n\n**Next Steps**:\n1. 本タスクドキュメントの承認取得\n2. Task 1.1 から順次実装開始\n3. 各タスク完了後に implementation log を記録\n",
  "fileStats": {
    "size": 44963,
    "lines": 568,
    "lastModified": "2025-12-14T14:48:56.473Z"
  },
  "comments": []
}